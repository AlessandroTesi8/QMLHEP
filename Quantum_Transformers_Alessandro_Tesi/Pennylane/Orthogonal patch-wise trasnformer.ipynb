{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pennylane","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-20T15:06:29.212464Z","iopub.execute_input":"2024-08-20T15:06:29.212764Z","iopub.status.idle":"2024-08-20T15:06:47.091654Z","shell.execute_reply.started":"2024-08-20T15:06:29.212736Z","shell.execute_reply":"2024-08-20T15:06:47.090584Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pennylane\n  Downloading PennyLane-0.37.0-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: numpy<2.0 in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.11.4)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from pennylane) (3.2.1)\nCollecting rustworkx (from pennylane)\n  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\nCollecting autograd (from pennylane)\n  Downloading autograd-1.6.2-py3-none-any.whl.metadata (706 bytes)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from pennylane) (0.10.2)\nRequirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.4.4)\nCollecting semantic-version>=2.7 (from pennylane)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting autoray>=0.6.11 (from pennylane)\n  Downloading autoray-0.6.12-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from pennylane) (4.2.4)\nCollecting pennylane-lightning>=0.37 (from pennylane)\n  Downloading PennyLane_Lightning-0.37.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (23 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pennylane) (2.32.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from pennylane) (4.9.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pennylane) (21.3)\nRequirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.10/site-packages (from autograd->pennylane) (1.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->pennylane) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (2024.7.4)\nDownloading PennyLane-0.37.0-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading autoray-0.6.12-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading PennyLane_Lightning-0.37.0-cp310-cp310-manylinux_2_28_x86_64.whl (15.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading autograd-1.6.2-py3-none-any.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: semantic-version, rustworkx, autoray, autograd, pennylane-lightning, pennylane\nSuccessfully installed autograd-1.6.2 autoray-0.6.12 pennylane-0.37.0 pennylane-lightning-0.37.0 rustworkx-0.15.1 semantic-version-2.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pennylane as qml\nfrom pennylane.operation import Operation\nimport numpy as np\nimport tensorflow as tf\n\n# Load MNIST dataset\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\n# Preprocess the data\nx_train = x_train[:25000]\ny_train = y_train[:25000]\nx_test = x_test[-5000:]\ny_test = y_test[-5000:]\n\n# Rescale the images\nx_train = x_train.reshape(-1, 784) / 255.0\nx_test = x_test.reshape(-1, 784) / 255.0\n\ndef filter_36(x, y):\n    keep = (y == 3) | (y == 6)\n    x, y = x[keep], y[keep]\n    y = y == 3\n    return x, y\n\nx_train, y_train = filter_36(x_train, y_train)\nx_test, y_test = filter_36(x_test, y_test)\n\nclass RBSGate(Operation):\n    num_params = 1\n    num_wires = 2\n    par_domain = 'R'\n\n    def __init__(self, theta, wires):\n        super().__init__(theta, wires=wires)\n        self.theta = theta\n\n    @staticmethod\n    def compute_matrix(theta):\n        cos = tf.cos(theta)\n        sin = tf.sin(theta)\n        return tf.convert_to_tensor([\n            [1, 0, 0, 0],\n            [0, cos, sin, 0],\n            [0, -sin, cos, 0],\n            [0, 0, 0, 1]\n        ], dtype=tf.float64)\n\n    def adjoint(self):\n        return RBSGate(-self.parameters[0], wires=self.wires)\n\n    def label(self, decimals=None, base_label=None, **kwargs):\n        theta = self.parameters[0]\n        return f\"RBS({theta:.2f})\"\n\ndef convert_array(X):\n    alphas = tf.zeros(X.shape[:-1] + (X.shape[-1]-1,), dtype=X.dtype)\n    X_normd = tf.linalg.l2_normalize(X, axis=-1)\n    for i in range(X.shape[-1]-1):\n        prod_sin_alphas = tf.reduce_prod(tf.sin(alphas[..., :i]), axis=-1)\n        updated_value = tf.acos(X_normd[..., i] / prod_sin_alphas)\n        indices = tf.constant([[i]])\n        updates = tf.reshape(updated_value, [1])\n        alphas = tf.tensor_scatter_nd_update(alphas, indices, updates)\n    return alphas\n\ndef vector_loader(alphas, wires=None, is_x=True, is_conjugate=False):\n    if wires is None:\n        wires = list(range(len(alphas) + 1))\n    if is_x and not is_conjugate:\n        qml.PauliX(wires=wires[0])\n    if is_conjugate:\n        for i in range(len(wires) - 2, -1, -1):\n            qml.apply(RBSGate(-alphas[i], wires=[wires[i], wires[i+1]]))\n    else:\n        for i in range(len(wires) - 1):\n            qml.apply(RBSGate(alphas[i], wires=[wires[i], wires[i+1]]))\n    if is_x and is_conjugate:\n        qml.PauliX(wires=wires[0])\n\ndef pyramid_circuit(parameters, wires=None):\n    # If wires is None, use all qubits in the circuit\n    if wires is None:\n        length = len(qml.device.wires)\n    else:\n        # If wires is not None, ensure it's a list of qubits\n        length = len(wires)\n\n    k = 0\n\n    for i in range(2 * length - 2):\n        j = length - abs(length - 1 - i)\n\n        if i % 2:\n            for _ in range(j):\n                if _ % 2 == 0 and k < len(parameters):\n                    qml.apply(RBSGate(parameters[k], wires=([wires[_], wires[_ + 1]])))\n                    k += 1\n        else:\n            for _ in range(j):\n                if _ % 2 and k < len(parameters):\n                    qml.apply(RBSGate(parameters[k], wires=([wires[_], wires[_ + 1]])))\n                    k += 1","metadata":{"execution":{"iopub.status.busy":"2024-08-20T15:06:47.093564Z","iopub.execute_input":"2024-08-20T15:06:47.093886Z","iopub.status.idle":"2024-08-20T15:07:02.403981Z","shell.execute_reply.started":"2024-08-20T15:06:47.093856Z","shell.execute_reply":"2024-08-20T15:07:02.403136Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-20 15:06:51.839798: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-20 15:06:51.839925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-20 15:06:51.987971: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"dev1 = qml.device('default.qubit', wires=4)\n\n@qml.qnode(dev1, interface='tf', diff_method='backprop')\ndef quantum_model_pyramid(inputs, weights):\n    inputs = tf.cast(inputs, tf.float64)\n    weights = tf.cast(weights, tf.float64)\n    vector_loader(convert_array(inputs), wires=range(4))\n    pyramid_circuit(weights, wires=range(4))\n    return [qml.expval(qml.PauliZ(wire)) for wire in range(4)]\n\nweights_init_pyramid = np.random.normal(size=(6,), scale=np.pi/4)\nweights_pyramid = tf.Variable(weights_init_pyramid, dtype=tf.float64)\nclass HybridModel(tf.keras.Model):\n    def __init__(self, quantum_model_pyramid):\n        super(HybridModel, self).__init__()\n        self.quantum_model_pyramid = quantum_model_pyramid\n        # Classical layer to project 7x7 patches into a 4D space\n        self.classical_nn_patch = tf.keras.layers.Dense(4, activation='relu', dtype=tf.float64)\n        # Additional classical layers after the pyramid circuit\n        self.classical_nn_1 = tf.keras.layers.Dense(8, activation='relu', dtype=tf.float64)\n        # Change the final output layer to use sigmoid activation\n        self.classical_nn_2 = tf.keras.layers.Dense(1, activation='sigmoid', dtype=tf.float64)\n\n    def build(self, input_shape):\n        self.quantum_weights_p = self.add_weight(shape=(6,), initializer='random_normal', trainable=True, dtype=tf.float64)\n\n    def call(self, inputs):\n        inputs = tf.cast(inputs, tf.float64)\n        # Reshape the flattened input (28x28 = 784) back to its 2D form (28x28)\n        inputs = tf.reshape(inputs, [-1, 28, 28, 1])\n\n        # Extract 7x7 patches from the 28x28 input\n        patches = tf.image.extract_patches(images=inputs,\n                                           sizes=[1, 7, 7, 1],\n                                           strides=[1, 7, 7, 1],\n                                           rates=[1, 1, 1, 1],\n                                           padding='VALID')\n        # Flatten each 7x7 patch into a 49-dimensional vector\n        patches = tf.reshape(patches, [-1, 49])\n\n        # Apply the classical NN to project each patch into a 4D space\n        projected_patches = self.classical_nn_patch(patches)\n        \n        # Reshape the projected patches for processing by the pyramid circuit\n        projected_patches = tf.reshape(projected_patches, [-1, 4])\n\n        # Apply the pyramid circuit to each 4D space\n        quantum_outputs = tf.map_fn(lambda x: tf.stack(self.quantum_model_pyramid(x, self.quantum_weights_p)),\n                                    projected_patches, dtype=tf.float64)\n\n        quantum_outputs = tf.where(tf.math.is_nan(quantum_outputs), tf.zeros_like(quantum_outputs), quantum_outputs)\n        \n        # Flatten the quantum outputs\n        quantum_outputs = tf.reshape(quantum_outputs, [-1, 64])\n\n        # Additional classical NN layers after pyramid outputs\n        nn_output = self.classical_nn_1(quantum_outputs)\n        nn_output = self.classical_nn_2(nn_output)\n        \n        return nn_output\n\n\n# Create an instance of the modified HybridModel\nmodel = HybridModel(quantum_model_pyramid)\n\n\n# Use binary cross-entropy loss\nloss_fn = tf.keras.losses.BinaryCrossentropy()\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n\nx_train_small_tensor = tf.convert_to_tensor(x_train, dtype=tf.float64)\ny_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float64)  # Labels should be in range [0, 1] for binary cross-entropy\n\n@tf.function\ndef train_step(inputs, targets):\n    with tf.GradientTape() as tape:\n        predictions = model(inputs)\n        loss = loss_fn(targets, predictions)\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(predictions), targets), tf.float64))\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    return loss, accuracy\n\n@tf.function\ndef validation_step(inputs, targets):\n    predictions = model(inputs)\n    loss = loss_fn(targets, predictions)\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(predictions), targets), tf.float64))\n    return loss, accuracy\n\nx_test_small_tensor = tf.convert_to_tensor(x_test, dtype=tf.float64)\ny_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float64)\n\nepochs = 30\nfor epoch in range(epochs):\n    loss, acc = train_step(x_train_small_tensor, y_train_tensor)\n    val_loss, val_acc = validation_step(x_test_small_tensor, y_test_tensor)\n    print(f'Epoch {epoch + 1} ----------------------------------- \\n Train Loss: {loss.numpy()}, Train Accuracy: {acc.numpy()},  Validation Loss: {val_loss.numpy()}, Validation Accuracy: {val_acc.numpy()}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T15:07:02.405550Z","iopub.execute_input":"2024-08-20T15:07:02.406316Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"WARNING: AutoGraph could not transform <function validate_measurements at 0x7b410864c670> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: cannot use assignment expressions with function call (__autograph_generated_filern7gj5h4.py, line 96)\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function _gcd_import at 0x7b415fc37400> and will run it as-is.\nCause: Unable to locate the source code of <function _gcd_import at 0x7b415fc37400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function _c3_mro at 0x7b415f9c67a0> and will run it as-is.\nCause: for/else statement not yet supported\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","output_type":"stream"}]}]}